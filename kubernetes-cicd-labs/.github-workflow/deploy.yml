name: Secure CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION: us-west-2
  EKS_CLUSTER_NAME: portfoliotracker-eks
  DOCKER_IMAGE: portfoliotracker                 #REPLACE WITH IMAGE FROM YOUR DOCKERHUB
  NAMESPACE: portfoliotracker

jobs:
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

    - name: SAST with Semgrep
      uses: returntocorp/semgrep-action@v1
      with:
        config: auto

  build-and-scan:
    name: Build and Scan Container
    runs-on: ubuntu-latest
    needs: security-scan
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    outputs:
      image-tag: ${{ steps.image-tag.outputs.tag }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Generate image tag
      id: image-tag
      run: echo "tag=${{ github.sha }}" >> $GITHUB_OUTPUT

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Login to Docker Hub
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}

    - name: Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        platforms: linux/amd64
        push: false
        tags: ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ steps.image-tag.outputs.tag }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        load: true

    - name: Run Trivy vulnerability scanner on image
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: '${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ steps.image-tag.outputs.tag }}'
        format: 'sarif'
        output: 'trivy-image-results.sarif'

    - name: Upload Trivy image scan results
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-image-results.sarif'

    - name: Check for HIGH/CRITICAL vulnerabilities
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: '${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ steps.image-tag.outputs.tag }}'
        format: 'table'
        exit-code: '1'
        severity: 'HIGH,CRITICAL'

    - name: Push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        platforms: linux/amd64
        push: true
        tags: ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ steps.image-tag.outputs.tag }}
        cache-from: type=gha

  deploy:
    name: Deploy to EKS
    runs-on: ubuntu-latest
    needs: build-and-scan
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    environment: production
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER_NAME }}

    - name: Verify cluster connection
      run: |
        kubectl cluster-info
        kubectl get nodes

    - name: Create namespace if not exists
      run: |
        kubectl apply -f k8s-manifests/namespace.yaml

    - name: Update ServiceAccount with IAM role
      run: |
        # Get the IAM role ARN from Terraform output
        ROLE_ARN=$(aws sts get-caller-identity --query Account --output text)
        ROLE_ARN="arn:aws:iam::${ROLE_ARN}:role/${{ env.EKS_CLUSTER_NAME }}-app-role"
        
        # Update the ServiceAccount manifest
        sed -i "s|ROLE_ARN_PLACEHOLDER|${ROLE_ARN}|g" k8s-manifests/namespace.yaml
        kubectl apply -f k8s-manifests/namespace.yaml

    - name: Create/Update secrets
      run: |
        # Create secrets with base64 encoding
        DB_PASSWORD_B64=$(echo -n "${{ secrets.DB_PASSWORD }}" | base64 -w 0)
        JWT_SECRET_B64=$(echo -n "${{ secrets.JWT_SECRET }}" | base64 -w 0)
        API_KEY_B64=$(echo -n "${{ secrets.API_KEY }}" | base64 -w 0)
        
        # Update secret manifest
        sed -i "s|DB_PASSWORD: \"\"|DB_PASSWORD: ${DB_PASSWORD_B64}|g" k8s-manifests/application/secret.yaml
        sed -i "s|JWT_SECRET: \"\"|JWT_SECRET: ${JWT_SECRET_B64}|g" k8s-manifests/application/secret.yaml
        sed -i "s|API_KEY: \"\"|API_KEY: ${API_KEY_B64}|g" k8s-manifests/application/secret.yaml
        
        kubectl apply -f k8s-manifests/application/secret.yaml

    - name: Apply network policies
      run: |
        kubectl apply -f k8s-manifests/network-policy.yaml

    - name: Deploy application
      run: |
        # Update deployment with new image
        IMAGE_TAG="${{ needs.build-and-scan.outputs.image-tag }}"
        sed -i "s|DOCKER_IMAGE_PLACEHOLDER|${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${IMAGE_TAG}|g" k8s-manifests/application/deployment.yaml
        
        # Apply all application manifests
        kubectl apply -f k8s-manifests/application/

    - name: Wait for deployment
      run: |
        kubectl rollout status deployment/portfoliotracker -n ${{ env.NAMESPACE }} --timeout=300s

    - name: Verify deployment
      run: |
        kubectl get pods -n ${{ env.NAMESPACE }}
        kubectl get services -n ${{ env.NAMESPACE }}
        
        # Check pod security context
        kubectl get pods -n ${{ env.NAMESPACE }} -o jsonpath='{.items[0].spec.securityContext}'

    - name: Run security compliance checks
      run: |
        # Check if pods are running as non-root
        kubectl get pods -n ${{ env.NAMESPACE }} -o jsonpath='{.items[*].spec.securityContext.runAsNonRoot}'
        
        # Verify network policies are applied
        kubectl get networkpolicies -n ${{ env.NAMESPACE }}
        
        # Check resource limits
        kubectl describe pods -n ${{ env.NAMESPACE }} | grep -A 5 "Limits:"

  security-compliance:
    name: Security Compliance Verification
    runs-on: ubuntu-latest
    needs: deploy
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER_NAME }}

    - name: Install kube-score
      run: |
        wget https://github.com/zegl/kube-score/releases/download/v1.16.1/kube-score_1.16.1_linux_amd64.tar.gz
        tar xzf kube-score_1.16.1_linux_amd64.tar.gz
        chmod +x kube-score
        sudo mv kube-score /usr/local/bin/

    - name: Security compliance check
      run: |
        # Export current deployment for analysis
        kubectl get deployment portfoliotracker -n ${{ env.NAMESPACE }} -o yaml > deployment.yaml
        
        # Run kube-score analysis
        kube-score score deployment.yaml
        
        # Custom security checks
        echo "=== Custom Security Verification ==="
        
        # Check for privileged containers
        if kubectl get pods -n ${{ env.NAMESPACE }} -o jsonpath='{.items[*].spec.containers[*].securityContext.privileged}' | grep -q true; then
          echo "❌ FAIL: Privileged containers detected"
          exit 1
        else
          echo "✅ PASS: No privileged containers"
        fi
        
        # Check for containers running as root
        if kubectl get pods -n ${{ env.NAMESPACE }} -o jsonpath='{.items[*].spec.securityContext.runAsUser}' | grep -q '^0$'; then
          echo "❌ FAIL: Containers running as root detected"
          exit 1
        else
          echo "✅ PASS: No containers running as root"
        fi
        
        # Verify resource limits are set
        if ! kubectl get pods -n ${{ env.NAMESPACE }} -o jsonpath='{.items[*].spec.containers[*].resources.limits}' | grep -q memory; then
          echo "❌ FAIL: Missing resource limits"
          exit 1
        else
          echo "✅ PASS: Resource limits configured"
        fi
        
        echo "=== Security Compliance Check Complete ==="